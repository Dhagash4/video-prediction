{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5oKKua3xOnvW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim import Adam\n",
    "# from Seq2Seq import Seq2Seq\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import io\n",
    "import imageio\n",
    "from ipywidgets import widgets, HBox\n",
    "\n",
    "# from models.dcgan import *\n",
    "# from models.lstm import *\n",
    "from data.MMNIST.mmnist import *\n",
    "from utils.visualizations import *\n",
    "from utils.TrainerBaseline import *\n",
    "from models.vgg_baseline import *\n",
    "from torchsummary import summary\n",
    "# from utils.TrainerFP import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9359cc41d445cad6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9359cc41d445cad6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=tboard_logs/kth_2_resnet_convlstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]             640\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "         LeakyReLU-3           [-1, 64, 64, 64]               0\n",
      "         ConvBlock-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]          36,928\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "         LeakyReLU-7           [-1, 64, 64, 64]               0\n",
      "         ConvBlock-8           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10          [-1, 128, 32, 32]          73,856\n",
      "      BatchNorm2d-11          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-12          [-1, 128, 32, 32]               0\n",
      "        ConvBlock-13          [-1, 128, 32, 32]               0\n",
      "           Conv2d-14          [-1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-15          [-1, 128, 32, 32]             256\n",
      "        LeakyReLU-16          [-1, 128, 32, 32]               0\n",
      "        ConvBlock-17          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-18          [-1, 128, 16, 16]               0\n",
      "           Conv2d-19          [-1, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-20          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-21          [-1, 256, 16, 16]               0\n",
      "        ConvBlock-22          [-1, 256, 16, 16]               0\n",
      "           Conv2d-23          [-1, 256, 16, 16]         590,080\n",
      "      BatchNorm2d-24          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-25          [-1, 256, 16, 16]               0\n",
      "        ConvBlock-26          [-1, 256, 16, 16]               0\n",
      "           Conv2d-27          [-1, 256, 16, 16]         590,080\n",
      "      BatchNorm2d-28          [-1, 256, 16, 16]             512\n",
      "        LeakyReLU-29          [-1, 256, 16, 16]               0\n",
      "        ConvBlock-30          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-31            [-1, 256, 8, 8]               0\n",
      "================================================================\n",
      "Total params: 1,736,640\n",
      "Trainable params: 1,736,640\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 30.88\n",
      "Params size (MB): 6.62\n",
      "Estimated Total Size (MB): 37.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = VGGEncoder().to(device)\n",
    "summary(models,(1,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-639702b1ea1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmmnist_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/MMNIST/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmmnist_data_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "mmnist_data_dir = \"data/MMNIST/\" \n",
    "train_loader, val_loader,test_loader = MMNIST(mmnist_data_dir,batch_size = 1, seq_first = True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KTH Data Statistics:\n",
      "Train loader len: 8000, Total training sequences: 8000\n",
      "Val loader len: 1000, Total validation sequences: 1000\n",
      "Test loader len: 2000, Total testing sequences: 2000\n",
      "Shape of batch: torch.Size([1, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "batch_size =1\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(\"KTH Data Statistics:\")\n",
    "print(f\"Train loader len: {len(train_loader)}, Total training sequences: {len(train_loader) * batch_size}\")\n",
    "print(f\"Val loader len: {len(val_loader)}, Total validation sequences: {len(val_loader) * batch_size}\")\n",
    "print(f\"Test loader len: {len(test_loader)}, Total testing sequences: {len(test_loader) * batch_size}\")\n",
    "print(f\"Shape of batch: {sample_batch[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerBase(arch_type = \"resnet\", img_size = (1,64,64),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iter 8000: mse loss 120.32944 : 100%|██████████| 8000/8000 [25:20<00:00,  5.26it/s]\n",
      "Epoch 2 Iter 10466: mse loss 31.90181 :  31%|███       | 2466/8000 [07:42<17:18,  5.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c30ea820a586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/video-prediction/code/utils/TrainerBaseline.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, val_loader, test_loader, num_epochs, device, init_step)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mepoch_mse\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {i+1} Iter {niter+1}: mse loss {epoch_mse:.5f} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/video-prediction/code/utils/TrainerBaseline.py\u001b[0m in \u001b[0;36mtrain_one_step\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mlstm_ouputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_ouputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mh_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mmse\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/video-prediction/code/models/vgg_baseline.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# encoded_skips.append(v1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;31m# encoded_skips.append(v2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/video-prediction/code/models/vgg_baseline.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader,val_loader,test_loader,num_epochs=11,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGGEncoder(\n",
       "  (vgg_block1): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (module): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (module): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (convlstm1): predictor_lstm(\n",
       "    (conv_lstms): ModuleList(\n",
       "      (0): ConvLSTMCell(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      )\n",
       "      (1): ConvLSTMCell(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vgg_block2): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (module): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (module): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (convlstm2): predictor_lstm(\n",
       "    (conv_lstms): ModuleList(\n",
       "      (0): ConvLSTMCell(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      )\n",
       "      (1): ConvLSTMCell(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vgg_block3): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (module): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (module): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (module): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (convlstm3): predictor_lstm(\n",
       "    (conv_lstms): ModuleList(\n",
       "      (0): ConvLSTMCell(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      )\n",
       "      (1): ConvLSTMCell(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.vgg_baseline import *\n",
    "model = VGGEncoder()\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [Sequential: 1-1, ConvBlock: 2-1, Sequential: 3-1, Conv2d: 4-1, BatchNorm2d: 4-2, LeakyReLU: 4-3, ConvBlock: 2-2, Sequential: 3-2, Conv2d: 4-4, BatchNorm2d: 4-5, LeakyReLU: 4-6, MaxPool2d: 2-3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\RWTH\\WS21-22\\Lab CudaVision\\video-prediction\\video-prediction\\code\\models\\vgg_baseline.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg_block1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mlstm1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvlstm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\RWTH\\WS21-22\\Lab CudaVision\\video-prediction\\video-prediction\\code\\models\\convlstm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden_state)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                 h, c = self.conv_lstms[i](x=cur_layer_input[:, t, :, :, :],\n\u001b[0m\u001b[0;32m    128\u001b[0m                                                  cur_state=[h, c])\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\RWTH\\WS21-22\\Lab CudaVision\\video-prediction\\video-prediction\\code\\models\\convlstm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, cur_state)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mconcat_input_hcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_cur\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mconcat_input_hcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_input_hcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 2 but got size 40 for tensor number 1 in the list.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6860/2351016180.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mexecuted_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msummary_list\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    144\u001b[0m                 \u001b[1;34m\"Failed to run torchsummary. See above stack traces for more details. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                 \u001b[1;34m\"Executed layers up to: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecuted_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [Sequential: 1-1, ConvBlock: 2-1, Sequential: 3-1, Conv2d: 4-1, BatchNorm2d: 4-2, LeakyReLU: 4-3, ConvBlock: 2-2, Sequential: 3-2, Conv2d: 4-4, BatchNorm2d: 4-5, LeakyReLU: 4-6, MaxPool2d: 2-3]"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_stats(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a, b = [5,[6,7,8]]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
      "|    └─ConvBlock: 2-1                    [-1, 64, 64, 64]          --\n",
      "|    |    └─Sequential: 3-1              [-1, 64, 64, 64]          768\n",
      "|    └─ConvBlock: 2-2                    [-1, 64, 64, 64]          --\n",
      "|    |    └─Sequential: 3-2              [-1, 64, 64, 64]          37,056\n",
      "|    └─MaxPool2d: 2-3                    [-1, 64, 32, 32]          --\n",
      "├─Sequential: 1-2                        [-1, 128, 16, 16]         --\n",
      "|    └─ConvBlock: 2-4                    [-1, 128, 32, 32]         --\n",
      "|    |    └─Sequential: 3-3              [-1, 128, 32, 32]         74,112\n",
      "|    └─ConvBlock: 2-5                    [-1, 128, 32, 32]         --\n",
      "|    |    └─Sequential: 3-4              [-1, 128, 32, 32]         147,840\n",
      "|    └─MaxPool2d: 2-6                    [-1, 128, 16, 16]         --\n",
      "├─Sequential: 1-3                        [-1, 256, 8, 8]           --\n",
      "|    └─ConvBlock: 2-7                    [-1, 256, 16, 16]         --\n",
      "|    |    └─Sequential: 3-5              [-1, 256, 16, 16]         295,680\n",
      "|    └─ConvBlock: 2-8                    [-1, 256, 16, 16]         --\n",
      "|    |    └─Sequential: 3-6              [-1, 256, 16, 16]         590,592\n",
      "|    └─ConvBlock: 2-9                    [-1, 256, 16, 16]         --\n",
      "|    |    └─Sequential: 3-7              [-1, 256, 16, 16]         590,592\n",
      "|    └─MaxPool2d: 2-10                   [-1, 256, 8, 8]           --\n",
      "├─Sequential: 1-4                        [-1, 128, 8, 8]           --\n",
      "|    └─Conv2d: 2-11                      [-1, 128, 8, 8]           295,040\n",
      "|    └─BatchNorm2d: 2-12                 [-1, 128, 8, 8]           256\n",
      "|    └─Tanh: 2-13                        [-1, 128, 8, 8]           --\n",
      "==========================================================================================\n",
      "Total params: 2,031,936\n",
      "Trainable params: 2,031,936\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 781.71\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 15.12\n",
      "Params size (MB): 7.75\n",
      "Estimated Total Size (MB): 22.89\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
       "|    └─ConvBlock: 2-1                    [-1, 64, 64, 64]          --\n",
       "|    |    └─Sequential: 3-1              [-1, 64, 64, 64]          768\n",
       "|    └─ConvBlock: 2-2                    [-1, 64, 64, 64]          --\n",
       "|    |    └─Sequential: 3-2              [-1, 64, 64, 64]          37,056\n",
       "|    └─MaxPool2d: 2-3                    [-1, 64, 32, 32]          --\n",
       "├─Sequential: 1-2                        [-1, 128, 16, 16]         --\n",
       "|    └─ConvBlock: 2-4                    [-1, 128, 32, 32]         --\n",
       "|    |    └─Sequential: 3-3              [-1, 128, 32, 32]         74,112\n",
       "|    └─ConvBlock: 2-5                    [-1, 128, 32, 32]         --\n",
       "|    |    └─Sequential: 3-4              [-1, 128, 32, 32]         147,840\n",
       "|    └─MaxPool2d: 2-6                    [-1, 128, 16, 16]         --\n",
       "├─Sequential: 1-3                        [-1, 256, 8, 8]           --\n",
       "|    └─ConvBlock: 2-7                    [-1, 256, 16, 16]         --\n",
       "|    |    └─Sequential: 3-5              [-1, 256, 16, 16]         295,680\n",
       "|    └─ConvBlock: 2-8                    [-1, 256, 16, 16]         --\n",
       "|    |    └─Sequential: 3-6              [-1, 256, 16, 16]         590,592\n",
       "|    └─ConvBlock: 2-9                    [-1, 256, 16, 16]         --\n",
       "|    |    └─Sequential: 3-7              [-1, 256, 16, 16]         590,592\n",
       "|    └─MaxPool2d: 2-10                   [-1, 256, 8, 8]           --\n",
       "├─Sequential: 1-4                        [-1, 128, 8, 8]           --\n",
       "|    └─Conv2d: 2-11                      [-1, 128, 8, 8]           295,040\n",
       "|    └─BatchNorm2d: 2-12                 [-1, 128, 8, 8]           256\n",
       "|    └─Tanh: 2-13                        [-1, 128, 8, 8]           --\n",
       "==========================================================================================\n",
       "Total params: 2,031,936\n",
       "Trainable params: 2,031,936\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 781.71\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 15.12\n",
       "Params size (MB): 7.75\n",
       "Estimated Total Size (MB): 22.89\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.vgg import VGGEncoder, VGGDecoder\n",
    "model = VGGEncoder(in_size = (1, 64, 64))\n",
    "model = model.to(device)\n",
    "from torchsummary import summary\n",
    "summary(model, (1,64,64))\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vgg import VGGEncoder, VGGDecoder\n",
    "model = VGGDecoder(out_size = (1, 128, 128))\n",
    "model = model.to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─ConvTranspose2d: 1-1                        [-1, 512, 8, 8]           590,336\n",
      "├─Sequential: 1-2                             [-1, 256, 16, 16]         --\n",
      "|    └─ConvBlock: 2-1                         [-1, 512, 8, 8]           --\n",
      "|    |    └─Sequential: 3-1                   [-1, 512, 8, 8]           2,360,832\n",
      "|    └─ConvBlock: 2-2                         [-1, 512, 8, 8]           --\n",
      "|    |    └─Sequential: 3-2                   [-1, 512, 8, 8]           2,360,832\n",
      "|    └─ConvTransposeBlock: 2-3                [-1, 256, 16, 16]         --\n",
      "|    |    └─Sequential: 3-3                   [-1, 256, 16, 16]         2,097,920\n",
      "├─Sequential: 1-3                             [-1, 128, 32, 32]         --\n",
      "|    └─ConvBlock: 2-4                         [-1, 256, 16, 16]         --\n",
      "|    |    └─Sequential: 3-4                   [-1, 256, 16, 16]         590,592\n",
      "|    └─ConvBlock: 2-5                         [-1, 256, 16, 16]         --\n",
      "|    |    └─Sequential: 3-5                   [-1, 256, 16, 16]         590,592\n",
      "|    └─ConvTransposeBlock: 2-6                [-1, 128, 32, 32]         --\n",
      "|    |    └─Sequential: 3-6                   [-1, 128, 32, 32]         524,672\n",
      "├─Sequential: 1-4                             [-1, 64, 64, 64]          --\n",
      "|    └─ConvBlock: 2-7                         [-1, 128, 32, 32]         --\n",
      "|    |    └─Sequential: 3-7                   [-1, 128, 32, 32]         147,840\n",
      "|    └─ConvTransposeBlock: 2-8                [-1, 64, 64, 64]          --\n",
      "|    |    └─Sequential: 3-8                   [-1, 64, 64, 64]          131,264\n",
      "├─Sequential: 1-5                             [-1, 1, 128, 128]         --\n",
      "|    └─ConvBlock: 2-9                         [-1, 64, 64, 64]          --\n",
      "|    |    └─Sequential: 3-9                   [-1, 64, 64, 64]          37,056\n",
      "|    └─ConvTranspose2d: 2-10                  [-1, 1, 128, 128]         1,025\n",
      "|    └─Sigmoid: 2-11                          [-1, 1, 128, 128]         --\n",
      "===============================================================================================\n",
      "Total params: 9,432,961\n",
      "Trainable params: 9,432,961\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.60\n",
      "===============================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 16.38\n",
      "Params size (MB): 35.98\n",
      "Estimated Total Size (MB): 52.39\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─ConvTranspose2d: 1-1                        [-1, 512, 8, 8]           590,336\n",
       "├─Sequential: 1-2                             [-1, 256, 16, 16]         --\n",
       "|    └─ConvBlock: 2-1                         [-1, 512, 8, 8]           --\n",
       "|    |    └─Sequential: 3-1                   [-1, 512, 8, 8]           2,360,832\n",
       "|    └─ConvBlock: 2-2                         [-1, 512, 8, 8]           --\n",
       "|    |    └─Sequential: 3-2                   [-1, 512, 8, 8]           2,360,832\n",
       "|    └─ConvTransposeBlock: 2-3                [-1, 256, 16, 16]         --\n",
       "|    |    └─Sequential: 3-3                   [-1, 256, 16, 16]         2,097,920\n",
       "├─Sequential: 1-3                             [-1, 128, 32, 32]         --\n",
       "|    └─ConvBlock: 2-4                         [-1, 256, 16, 16]         --\n",
       "|    |    └─Sequential: 3-4                   [-1, 256, 16, 16]         590,592\n",
       "|    └─ConvBlock: 2-5                         [-1, 256, 16, 16]         --\n",
       "|    |    └─Sequential: 3-5                   [-1, 256, 16, 16]         590,592\n",
       "|    └─ConvTransposeBlock: 2-6                [-1, 128, 32, 32]         --\n",
       "|    |    └─Sequential: 3-6                   [-1, 128, 32, 32]         524,672\n",
       "├─Sequential: 1-4                             [-1, 64, 64, 64]          --\n",
       "|    └─ConvBlock: 2-7                         [-1, 128, 32, 32]         --\n",
       "|    |    └─Sequential: 3-7                   [-1, 128, 32, 32]         147,840\n",
       "|    └─ConvTransposeBlock: 2-8                [-1, 64, 64, 64]          --\n",
       "|    |    └─Sequential: 3-8                   [-1, 64, 64, 64]          131,264\n",
       "├─Sequential: 1-5                             [-1, 1, 128, 128]         --\n",
       "|    └─ConvBlock: 2-9                         [-1, 64, 64, 64]          --\n",
       "|    |    └─Sequential: 3-9                   [-1, 64, 64, 64]          37,056\n",
       "|    └─ConvTranspose2d: 2-10                  [-1, 1, 128, 128]         1,025\n",
       "|    └─Sigmoid: 2-11                          [-1, 1, 128, 128]         --\n",
       "===============================================================================================\n",
       "Total params: 9,432,961\n",
       "Trainable params: 9,432,961\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.60\n",
       "===============================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 16.38\n",
       "Params size (MB): 35.98\n",
       "Estimated Total Size (MB): 52.39\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, ((256,8,8),[(64,16,16)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 512, 2, 2]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 64, 64]          1,792\n",
      "|    └─ReLU: 2-2                         [-1, 64, 64, 64]          --\n",
      "|    └─Conv2d: 2-3                       [-1, 64, 64, 64]          36,928\n",
      "|    └─ReLU: 2-4                         [-1, 64, 64, 64]          --\n",
      "|    └─MaxPool2d: 2-5                    [-1, 64, 32, 32]          --\n",
      "|    └─Conv2d: 2-6                       [-1, 128, 32, 32]         73,856\n",
      "|    └─ReLU: 2-7                         [-1, 128, 32, 32]         --\n",
      "|    └─Conv2d: 2-8                       [-1, 128, 32, 32]         147,584\n",
      "|    └─ReLU: 2-9                         [-1, 128, 32, 32]         --\n",
      "|    └─MaxPool2d: 2-10                   [-1, 128, 16, 16]         --\n",
      "|    └─Conv2d: 2-11                      [-1, 256, 16, 16]         295,168\n",
      "|    └─ReLU: 2-12                        [-1, 256, 16, 16]         --\n",
      "|    └─Conv2d: 2-13                      [-1, 256, 16, 16]         590,080\n",
      "|    └─ReLU: 2-14                        [-1, 256, 16, 16]         --\n",
      "|    └─Conv2d: 2-15                      [-1, 256, 16, 16]         590,080\n",
      "|    └─ReLU: 2-16                        [-1, 256, 16, 16]         --\n",
      "|    └─MaxPool2d: 2-17                   [-1, 256, 8, 8]           --\n",
      "|    └─Conv2d: 2-18                      [-1, 512, 8, 8]           1,180,160\n",
      "|    └─ReLU: 2-19                        [-1, 512, 8, 8]           --\n",
      "|    └─Conv2d: 2-20                      [-1, 512, 8, 8]           2,359,808\n",
      "|    └─ReLU: 2-21                        [-1, 512, 8, 8]           --\n",
      "|    └─Conv2d: 2-22                      [-1, 512, 8, 8]           2,359,808\n",
      "|    └─ReLU: 2-23                        [-1, 512, 8, 8]           --\n",
      "|    └─MaxPool2d: 2-24                   [-1, 512, 4, 4]           --\n",
      "|    └─Conv2d: 2-25                      [-1, 512, 4, 4]           2,359,808\n",
      "|    └─ReLU: 2-26                        [-1, 512, 4, 4]           --\n",
      "|    └─Conv2d: 2-27                      [-1, 512, 4, 4]           2,359,808\n",
      "|    └─ReLU: 2-28                        [-1, 512, 4, 4]           --\n",
      "|    └─Conv2d: 2-29                      [-1, 512, 4, 4]           2,359,808\n",
      "|    └─ReLU: 2-30                        [-1, 512, 4, 4]           --\n",
      "|    └─MaxPool2d: 2-31                   [-1, 512, 2, 2]           --\n",
      "├─AdaptiveAvgPool2d: 1-2                 [-1, 512, 7, 7]           --\n",
      "├─Sequential: 1-3                        [-1, 1000]                --\n",
      "|    └─Linear: 2-32                      [-1, 4096]                102,764,544\n",
      "|    └─ReLU: 2-33                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-34                     [-1, 4096]                --\n",
      "|    └─Linear: 2-35                      [-1, 4096]                16,781,312\n",
      "|    └─ReLU: 2-36                        [-1, 4096]                --\n",
      "|    └─Dropout: 2-37                     [-1, 4096]                --\n",
      "|    └─Linear: 2-38                      [-1, 1000]                4,097,000\n",
      "==========================================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.51\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 8.51\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 536.35\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = DCGANEncoder(in_size = (1,128, 128))\n",
    "# model = model.to(device)\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "model = models.vgg16()\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, (3,64, 64))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet18Encoder(\n",
       "  (c1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlockEncoder(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualBlockEncoder(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlockEncoder(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlockEncoder(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlockEncoder(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlockEncoder(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResidualBlockEncoder(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlockEncoder(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (c6): Sequential(\n",
       "    (0): Conv2d(512, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.resnet import *\n",
    "\n",
    "model = Resnet18Encoder(in_size = (1,64,64))\n",
    "model = model.to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 64, 64]          576\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 64, 64]          128\n",
      "|    └─LeakyReLU: 2-3                    [-1, 64, 64, 64]          --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 64, 32, 32]          --\n",
      "├─Sequential: 1-2                        [-1, 64, 32, 32]          --\n",
      "|    └─ResidualBlockEncoder: 2-5         [-1, 64, 32, 32]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 32, 32]          36,864\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 32, 32]          128\n",
      "|    |    └─LeakyReLU: 3-3               [-1, 64, 32, 32]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 64, 32, 32]          36,864\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 64, 32, 32]          128\n",
      "|    |    └─LeakyReLU: 3-6               [-1, 64, 32, 32]          --\n",
      "|    └─ResidualBlockEncoder: 2-6         [-1, 64, 32, 32]          --\n",
      "|    |    └─Conv2d: 3-7                  [-1, 64, 32, 32]          36,864\n",
      "|    |    └─BatchNorm2d: 3-8             [-1, 64, 32, 32]          128\n",
      "|    |    └─LeakyReLU: 3-9               [-1, 64, 32, 32]          --\n",
      "|    |    └─Conv2d: 3-10                 [-1, 64, 32, 32]          36,864\n",
      "|    |    └─BatchNorm2d: 3-11            [-1, 64, 32, 32]          128\n",
      "|    |    └─LeakyReLU: 3-12              [-1, 64, 32, 32]          --\n",
      "├─Sequential: 1-3                        [-1, 128, 16, 16]         --\n",
      "|    └─ResidualBlockEncoder: 2-7         [-1, 128, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 128, 16, 16]         73,728\n",
      "|    |    └─BatchNorm2d: 3-14            [-1, 128, 16, 16]         256\n",
      "|    |    └─LeakyReLU: 3-15              [-1, 128, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-16                 [-1, 128, 16, 16]         147,456\n",
      "|    |    └─BatchNorm2d: 3-17            [-1, 128, 16, 16]         256\n",
      "|    |    └─Sequential: 3-18             [-1, 128, 16, 16]         8,576\n",
      "|    |    └─LeakyReLU: 3-19              [-1, 128, 16, 16]         --\n",
      "|    └─ResidualBlockEncoder: 2-8         [-1, 128, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-20                 [-1, 128, 16, 16]         147,456\n",
      "|    |    └─BatchNorm2d: 3-21            [-1, 128, 16, 16]         256\n",
      "|    |    └─LeakyReLU: 3-22              [-1, 128, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-23                 [-1, 128, 16, 16]         147,456\n",
      "|    |    └─BatchNorm2d: 3-24            [-1, 128, 16, 16]         256\n",
      "|    |    └─LeakyReLU: 3-25              [-1, 128, 16, 16]         --\n",
      "├─Sequential: 1-4                        [-1, 256, 8, 8]           --\n",
      "|    └─ResidualBlockEncoder: 2-9         [-1, 256, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-26                 [-1, 256, 8, 8]           294,912\n",
      "|    |    └─BatchNorm2d: 3-27            [-1, 256, 8, 8]           512\n",
      "|    |    └─LeakyReLU: 3-28              [-1, 256, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-29                 [-1, 256, 8, 8]           589,824\n",
      "|    |    └─BatchNorm2d: 3-30            [-1, 256, 8, 8]           512\n",
      "|    |    └─Sequential: 3-31             [-1, 256, 8, 8]           33,536\n",
      "|    |    └─LeakyReLU: 3-32              [-1, 256, 8, 8]           --\n",
      "|    └─ResidualBlockEncoder: 2-10        [-1, 256, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-33                 [-1, 256, 8, 8]           589,824\n",
      "|    |    └─BatchNorm2d: 3-34            [-1, 256, 8, 8]           512\n",
      "|    |    └─LeakyReLU: 3-35              [-1, 256, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-36                 [-1, 256, 8, 8]           589,824\n",
      "|    |    └─BatchNorm2d: 3-37            [-1, 256, 8, 8]           512\n",
      "|    |    └─LeakyReLU: 3-38              [-1, 256, 8, 8]           --\n",
      "├─Sequential: 1-5                        [-1, 512, 4, 4]           --\n",
      "|    └─ResidualBlockEncoder: 2-11        [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-39                 [-1, 512, 4, 4]           1,179,648\n",
      "|    |    └─BatchNorm2d: 3-40            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─LeakyReLU: 3-41              [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-42                 [-1, 512, 4, 4]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-43            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─Sequential: 3-44             [-1, 512, 4, 4]           132,608\n",
      "|    |    └─LeakyReLU: 3-45              [-1, 512, 4, 4]           --\n",
      "|    └─ResidualBlockEncoder: 2-12        [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-46                 [-1, 512, 4, 4]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-47            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─LeakyReLU: 3-48              [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-49                 [-1, 512, 4, 4]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-50            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─LeakyReLU: 3-51              [-1, 512, 4, 4]           --\n",
      "├─Sequential: 1-6                        [-1, 128, 1, 1]           --\n",
      "|    └─Conv2d: 2-13                      [-1, 128, 1, 1]           1,048,704\n",
      "|    └─BatchNorm2d: 2-14                 [-1, 128, 1, 1]           256\n",
      "|    └─Tanh: 2-15                        [-1, 128, 1, 1]           --\n",
      "==========================================================================================\n",
      "Total params: 12,217,536\n",
      "Trainable params: 12,217,536\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 580.61\n",
      "==========================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 12.38\n",
      "Params size (MB): 46.61\n",
      "Estimated Total Size (MB): 59.00\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 32, 32]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 64, 64]          576\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 64, 64]          128\n",
       "|    └─LeakyReLU: 2-3                    [-1, 64, 64, 64]          --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 64, 32, 32]          --\n",
       "├─Sequential: 1-2                        [-1, 64, 32, 32]          --\n",
       "|    └─ResidualBlockEncoder: 2-5         [-1, 64, 32, 32]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 32, 32]          36,864\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 32, 32]          128\n",
       "|    |    └─LeakyReLU: 3-3               [-1, 64, 32, 32]          --\n",
       "|    |    └─Conv2d: 3-4                  [-1, 64, 32, 32]          36,864\n",
       "|    |    └─BatchNorm2d: 3-5             [-1, 64, 32, 32]          128\n",
       "|    |    └─LeakyReLU: 3-6               [-1, 64, 32, 32]          --\n",
       "|    └─ResidualBlockEncoder: 2-6         [-1, 64, 32, 32]          --\n",
       "|    |    └─Conv2d: 3-7                  [-1, 64, 32, 32]          36,864\n",
       "|    |    └─BatchNorm2d: 3-8             [-1, 64, 32, 32]          128\n",
       "|    |    └─LeakyReLU: 3-9               [-1, 64, 32, 32]          --\n",
       "|    |    └─Conv2d: 3-10                 [-1, 64, 32, 32]          36,864\n",
       "|    |    └─BatchNorm2d: 3-11            [-1, 64, 32, 32]          128\n",
       "|    |    └─LeakyReLU: 3-12              [-1, 64, 32, 32]          --\n",
       "├─Sequential: 1-3                        [-1, 128, 16, 16]         --\n",
       "|    └─ResidualBlockEncoder: 2-7         [-1, 128, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-13                 [-1, 128, 16, 16]         73,728\n",
       "|    |    └─BatchNorm2d: 3-14            [-1, 128, 16, 16]         256\n",
       "|    |    └─LeakyReLU: 3-15              [-1, 128, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-16                 [-1, 128, 16, 16]         147,456\n",
       "|    |    └─BatchNorm2d: 3-17            [-1, 128, 16, 16]         256\n",
       "|    |    └─Sequential: 3-18             [-1, 128, 16, 16]         8,576\n",
       "|    |    └─LeakyReLU: 3-19              [-1, 128, 16, 16]         --\n",
       "|    └─ResidualBlockEncoder: 2-8         [-1, 128, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-20                 [-1, 128, 16, 16]         147,456\n",
       "|    |    └─BatchNorm2d: 3-21            [-1, 128, 16, 16]         256\n",
       "|    |    └─LeakyReLU: 3-22              [-1, 128, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-23                 [-1, 128, 16, 16]         147,456\n",
       "|    |    └─BatchNorm2d: 3-24            [-1, 128, 16, 16]         256\n",
       "|    |    └─LeakyReLU: 3-25              [-1, 128, 16, 16]         --\n",
       "├─Sequential: 1-4                        [-1, 256, 8, 8]           --\n",
       "|    └─ResidualBlockEncoder: 2-9         [-1, 256, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-26                 [-1, 256, 8, 8]           294,912\n",
       "|    |    └─BatchNorm2d: 3-27            [-1, 256, 8, 8]           512\n",
       "|    |    └─LeakyReLU: 3-28              [-1, 256, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-29                 [-1, 256, 8, 8]           589,824\n",
       "|    |    └─BatchNorm2d: 3-30            [-1, 256, 8, 8]           512\n",
       "|    |    └─Sequential: 3-31             [-1, 256, 8, 8]           33,536\n",
       "|    |    └─LeakyReLU: 3-32              [-1, 256, 8, 8]           --\n",
       "|    └─ResidualBlockEncoder: 2-10        [-1, 256, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-33                 [-1, 256, 8, 8]           589,824\n",
       "|    |    └─BatchNorm2d: 3-34            [-1, 256, 8, 8]           512\n",
       "|    |    └─LeakyReLU: 3-35              [-1, 256, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-36                 [-1, 256, 8, 8]           589,824\n",
       "|    |    └─BatchNorm2d: 3-37            [-1, 256, 8, 8]           512\n",
       "|    |    └─LeakyReLU: 3-38              [-1, 256, 8, 8]           --\n",
       "├─Sequential: 1-5                        [-1, 512, 4, 4]           --\n",
       "|    └─ResidualBlockEncoder: 2-11        [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-39                 [-1, 512, 4, 4]           1,179,648\n",
       "|    |    └─BatchNorm2d: 3-40            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─LeakyReLU: 3-41              [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-42                 [-1, 512, 4, 4]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-43            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─Sequential: 3-44             [-1, 512, 4, 4]           132,608\n",
       "|    |    └─LeakyReLU: 3-45              [-1, 512, 4, 4]           --\n",
       "|    └─ResidualBlockEncoder: 2-12        [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-46                 [-1, 512, 4, 4]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-47            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─LeakyReLU: 3-48              [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-49                 [-1, 512, 4, 4]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-50            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─LeakyReLU: 3-51              [-1, 512, 4, 4]           --\n",
       "├─Sequential: 1-6                        [-1, 128, 1, 1]           --\n",
       "|    └─Conv2d: 2-13                      [-1, 128, 1, 1]           1,048,704\n",
       "|    └─BatchNorm2d: 2-14                 [-1, 128, 1, 1]           256\n",
       "|    └─Tanh: 2-15                        [-1, 128, 1, 1]           --\n",
       "==========================================================================================\n",
       "Total params: 12,217,536\n",
       "Trainable params: 12,217,536\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 580.61\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 12.38\n",
       "Params size (MB): 46.61\n",
       "Estimated Total Size (MB): 59.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmnist_data_dir = \"data/MMNIST/\" \n",
    "train_loader, val_loader,test_loader = MMNIST(mmnist_data_dir,batch_size = 20, seq_first = True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = next(iter(val_loader))\n",
    "b1 = next(iter(val_loader))\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_grid_batch(b, b1, nsamples = 5, text = \"random\", batch_first = False, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pred_gifs(b, nsamples=5, text = \"test\", batch_first = False, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.KTH.kth import *\n",
    "from data.MMNIST.mmnist import *\n",
    "\n",
    "kth_data_dir = \"data/KTH/kth/\"\n",
    "mmnist_data_dir = \"data/MMNIST/\" \n",
    "\n",
    "batch_size = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, val_loader,test_loader = get_KTH(kth_data_dir, batch_size = 20, seq_first=True, frame_skip=20, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(\"KTH Data Statistics:\")\n",
    "print(f\"Train loader len: {len(train_loader)}, Total training sequences: {len(train_loader) * batch_size}\")\n",
    "print(f\"Val loader len: {len(val_loader)}, Total validation sequences: {len(val_loader) * batch_size}\")\n",
    "print(f\"Test loader len: {len(test_loader)}, Total testing sequences: {len(test_loader) * batch_size}\")\n",
    "print(f\"Shape of batch: {sample_batch[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_loader:\n",
    "    print(x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.TrainerNP import *\n",
    "trainer = TrainerNP(arch_type = \"resnet\", img_size = (1,128,128),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/ranaa0/video-prediction/code/data/KTH/kth.py:134: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch[i]['seq'] = torch.tensor(batch[i]['seq']) / 255.0\n",
      "  0%|                                                                                                                                                                                                                                                                                                | 0/191 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 10.76 GiB total capacity; 9.53 GiB already allocated; 66.50 MiB free; 9.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/video-prediction/code/utils/TrainerNP.py:142\u001b[0m, in \u001b[0;36mTrainerNP.train\u001b[0;34m(self, train_loader, val_loader, test_loader, num_epochs, device, init_step)\u001b[0m\n\u001b[1;32m    140\u001b[0m     seqs \u001b[38;5;241m=\u001b[39m seqs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    141\u001b[0m seqs \u001b[38;5;241m=\u001b[39m seqs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 142\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m epoch_mse\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mmse\n\u001b[1;32m    144\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Iter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mniter\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: mse loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_mse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/video-prediction/code/utils/TrainerNP.py:60\u001b[0m, in \u001b[0;36mTrainerNP.train_one_step\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39minit_state()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# print(\"hello\")\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m h_seq \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpast_frames\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_frames)]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# print(h_seq[0][0].shape)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m mse \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/video-prediction/code/utils/TrainerNP.py:60\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39minit_state()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# print(\"hello\")\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m h_seq \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpast_frames\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_frames)]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# print(h_seq[0][0].shape)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m mse \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/visionproject/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/video-prediction/code/models/resnet.py:121\u001b[0m, in \u001b[0;36mResnet18Encoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    117\u001b[0m     \n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m#output list for skip connection\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     encoded_skip \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     encoded_skip\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    124\u001b[0m     l1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(\u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/visionproject/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/visionproject/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/visionproject/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/visionproject/lib/python3.9/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/visionproject/lib/python3.9/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 10.76 GiB total capacity; 9.53 GiB already allocated; 66.50 MiB free; 9.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader, val_loader,test_loader, device =device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DCGANEncoder(in_size=(1,128,128))\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-1pHZ9zocxm"
   },
   "source": [
    "#**LSTM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwhibs5vohGo"
   },
   "source": [
    "#**DCGAN encoder and decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8sv829K4fpj",
    "outputId": "ecedb48c-6c6a-42c6-ea1e-bbe3fa06ba7f"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(100, 512, 4, 4)\n",
    "y = torch.cat([x,x],1)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7skSZs_NO4K",
    "outputId": "7881ac19-dc78-44ea-eec9-185f47693137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 64, 64, 64]          --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 128, 128]        576\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 128, 128]        128\n",
      "|    └─ReLU: 2-3                         [-1, 64, 128, 128]        --\n",
      "|    └─MaxPool2d: 2-4                    [-1, 64, 64, 64]          --\n",
      "├─Sequential: 1-2                        [-1, 64, 64, 64]          --\n",
      "|    └─ResidualBlockEncoder: 2-5         [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 64, 64]          36,864\n",
      "|    |    └─BatchNorm2d: 3-2             [-1, 64, 64, 64]          128\n",
      "|    |    └─ReLU: 3-3                    [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-4                  [-1, 64, 64, 64]          36,864\n",
      "|    |    └─BatchNorm2d: 3-5             [-1, 64, 64, 64]          128\n",
      "|    └─ResidualBlockEncoder: 2-6         [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-6                  [-1, 64, 64, 64]          36,864\n",
      "|    |    └─BatchNorm2d: 3-7             [-1, 64, 64, 64]          128\n",
      "|    |    └─ReLU: 3-8                    [-1, 64, 64, 64]          --\n",
      "|    |    └─Conv2d: 3-9                  [-1, 64, 64, 64]          36,864\n",
      "|    |    └─BatchNorm2d: 3-10            [-1, 64, 64, 64]          128\n",
      "├─Sequential: 1-3                        [-1, 128, 32, 32]         --\n",
      "|    └─ResidualBlockEncoder: 2-7         [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-11                 [-1, 128, 32, 32]         73,728\n",
      "|    |    └─BatchNorm2d: 3-12            [-1, 128, 32, 32]         256\n",
      "|    |    └─ReLU: 3-13                   [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-14                 [-1, 128, 32, 32]         147,456\n",
      "|    |    └─BatchNorm2d: 3-15            [-1, 128, 32, 32]         256\n",
      "|    |    └─Sequential: 3-16             [-1, 128, 32, 32]         8,576\n",
      "|    └─ResidualBlockEncoder: 2-8         [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-17                 [-1, 128, 32, 32]         147,456\n",
      "|    |    └─BatchNorm2d: 3-18            [-1, 128, 32, 32]         256\n",
      "|    |    └─ReLU: 3-19                   [-1, 128, 32, 32]         --\n",
      "|    |    └─Conv2d: 3-20                 [-1, 128, 32, 32]         147,456\n",
      "|    |    └─BatchNorm2d: 3-21            [-1, 128, 32, 32]         256\n",
      "├─Sequential: 1-4                        [-1, 256, 16, 16]         --\n",
      "|    └─ResidualBlockEncoder: 2-9         [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-22                 [-1, 256, 16, 16]         294,912\n",
      "|    |    └─BatchNorm2d: 3-23            [-1, 256, 16, 16]         512\n",
      "|    |    └─ReLU: 3-24                   [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-25                 [-1, 256, 16, 16]         589,824\n",
      "|    |    └─BatchNorm2d: 3-26            [-1, 256, 16, 16]         512\n",
      "|    |    └─Sequential: 3-27             [-1, 256, 16, 16]         33,536\n",
      "|    └─ResidualBlockEncoder: 2-10        [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-28                 [-1, 256, 16, 16]         589,824\n",
      "|    |    └─BatchNorm2d: 3-29            [-1, 256, 16, 16]         512\n",
      "|    |    └─ReLU: 3-30                   [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-31                 [-1, 256, 16, 16]         589,824\n",
      "|    |    └─BatchNorm2d: 3-32            [-1, 256, 16, 16]         512\n",
      "├─Sequential: 1-5                        [-1, 512, 8, 8]           --\n",
      "|    └─ResidualBlockEncoder: 2-11        [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-33                 [-1, 512, 8, 8]           1,179,648\n",
      "|    |    └─BatchNorm2d: 3-34            [-1, 512, 8, 8]           1,024\n",
      "|    |    └─ReLU: 3-35                   [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-36                 [-1, 512, 8, 8]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-37            [-1, 512, 8, 8]           1,024\n",
      "|    |    └─Sequential: 3-38             [-1, 512, 8, 8]           132,608\n",
      "|    └─ResidualBlockEncoder: 2-12        [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-39                 [-1, 512, 8, 8]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-40            [-1, 512, 8, 8]           1,024\n",
      "|    |    └─ReLU: 3-41                   [-1, 512, 8, 8]           --\n",
      "|    |    └─Conv2d: 3-42                 [-1, 512, 8, 8]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-43            [-1, 512, 8, 8]           1,024\n",
      "├─Sequential: 1-6                        [-1, 512, 4, 4]           --\n",
      "|    └─ResidualBlockEncoder: 2-13        [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-44                 [-1, 512, 4, 4]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-45            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─ReLU: 3-46                   [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-47                 [-1, 512, 4, 4]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-48            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─Sequential: 3-49             [-1, 512, 4, 4]           263,680\n",
      "|    └─ResidualBlockEncoder: 2-14        [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-50                 [-1, 512, 4, 4]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-51            [-1, 512, 4, 4]           1,024\n",
      "|    |    └─ReLU: 3-52                   [-1, 512, 4, 4]           --\n",
      "|    |    └─Conv2d: 3-53                 [-1, 512, 4, 4]           2,359,296\n",
      "|    |    └─BatchNorm2d: 3-54            [-1, 512, 4, 4]           1,024\n",
      "├─Sequential: 1-7                        [-1, 128, 1, 1]           --\n",
      "|    └─Conv2d: 2-15                      [-1, 128, 1, 1]           1,048,704\n",
      "|    └─BatchNorm2d: 2-16                 [-1, 128, 1, 1]           256\n",
      "|    └─Tanh: 2-17                        [-1, 128, 1, 1]           --\n",
      "==========================================================================================\n",
      "Total params: 21,922,496\n",
      "Trainable params: 21,922,496\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.42\n",
      "==========================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 50.13\n",
      "Params size (MB): 83.63\n",
      "Estimated Total Size (MB): 133.82\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 64, 64, 64]          --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 128, 128]        576\n",
       "|    └─BatchNorm2d: 2-2                  [-1, 64, 128, 128]        128\n",
       "|    └─ReLU: 2-3                         [-1, 64, 128, 128]        --\n",
       "|    └─MaxPool2d: 2-4                    [-1, 64, 64, 64]          --\n",
       "├─Sequential: 1-2                        [-1, 64, 64, 64]          --\n",
       "|    └─ResidualBlockEncoder: 2-5         [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-1                  [-1, 64, 64, 64]          36,864\n",
       "|    |    └─BatchNorm2d: 3-2             [-1, 64, 64, 64]          128\n",
       "|    |    └─ReLU: 3-3                    [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-4                  [-1, 64, 64, 64]          36,864\n",
       "|    |    └─BatchNorm2d: 3-5             [-1, 64, 64, 64]          128\n",
       "|    └─ResidualBlockEncoder: 2-6         [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-6                  [-1, 64, 64, 64]          36,864\n",
       "|    |    └─BatchNorm2d: 3-7             [-1, 64, 64, 64]          128\n",
       "|    |    └─ReLU: 3-8                    [-1, 64, 64, 64]          --\n",
       "|    |    └─Conv2d: 3-9                  [-1, 64, 64, 64]          36,864\n",
       "|    |    └─BatchNorm2d: 3-10            [-1, 64, 64, 64]          128\n",
       "├─Sequential: 1-3                        [-1, 128, 32, 32]         --\n",
       "|    └─ResidualBlockEncoder: 2-7         [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-11                 [-1, 128, 32, 32]         73,728\n",
       "|    |    └─BatchNorm2d: 3-12            [-1, 128, 32, 32]         256\n",
       "|    |    └─ReLU: 3-13                   [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-14                 [-1, 128, 32, 32]         147,456\n",
       "|    |    └─BatchNorm2d: 3-15            [-1, 128, 32, 32]         256\n",
       "|    |    └─Sequential: 3-16             [-1, 128, 32, 32]         8,576\n",
       "|    └─ResidualBlockEncoder: 2-8         [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-17                 [-1, 128, 32, 32]         147,456\n",
       "|    |    └─BatchNorm2d: 3-18            [-1, 128, 32, 32]         256\n",
       "|    |    └─ReLU: 3-19                   [-1, 128, 32, 32]         --\n",
       "|    |    └─Conv2d: 3-20                 [-1, 128, 32, 32]         147,456\n",
       "|    |    └─BatchNorm2d: 3-21            [-1, 128, 32, 32]         256\n",
       "├─Sequential: 1-4                        [-1, 256, 16, 16]         --\n",
       "|    └─ResidualBlockEncoder: 2-9         [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-22                 [-1, 256, 16, 16]         294,912\n",
       "|    |    └─BatchNorm2d: 3-23            [-1, 256, 16, 16]         512\n",
       "|    |    └─ReLU: 3-24                   [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-25                 [-1, 256, 16, 16]         589,824\n",
       "|    |    └─BatchNorm2d: 3-26            [-1, 256, 16, 16]         512\n",
       "|    |    └─Sequential: 3-27             [-1, 256, 16, 16]         33,536\n",
       "|    └─ResidualBlockEncoder: 2-10        [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-28                 [-1, 256, 16, 16]         589,824\n",
       "|    |    └─BatchNorm2d: 3-29            [-1, 256, 16, 16]         512\n",
       "|    |    └─ReLU: 3-30                   [-1, 256, 16, 16]         --\n",
       "|    |    └─Conv2d: 3-31                 [-1, 256, 16, 16]         589,824\n",
       "|    |    └─BatchNorm2d: 3-32            [-1, 256, 16, 16]         512\n",
       "├─Sequential: 1-5                        [-1, 512, 8, 8]           --\n",
       "|    └─ResidualBlockEncoder: 2-11        [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-33                 [-1, 512, 8, 8]           1,179,648\n",
       "|    |    └─BatchNorm2d: 3-34            [-1, 512, 8, 8]           1,024\n",
       "|    |    └─ReLU: 3-35                   [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-36                 [-1, 512, 8, 8]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-37            [-1, 512, 8, 8]           1,024\n",
       "|    |    └─Sequential: 3-38             [-1, 512, 8, 8]           132,608\n",
       "|    └─ResidualBlockEncoder: 2-12        [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-39                 [-1, 512, 8, 8]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-40            [-1, 512, 8, 8]           1,024\n",
       "|    |    └─ReLU: 3-41                   [-1, 512, 8, 8]           --\n",
       "|    |    └─Conv2d: 3-42                 [-1, 512, 8, 8]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-43            [-1, 512, 8, 8]           1,024\n",
       "├─Sequential: 1-6                        [-1, 512, 4, 4]           --\n",
       "|    └─ResidualBlockEncoder: 2-13        [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-44                 [-1, 512, 4, 4]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-45            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─ReLU: 3-46                   [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-47                 [-1, 512, 4, 4]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-48            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─Sequential: 3-49             [-1, 512, 4, 4]           263,680\n",
       "|    └─ResidualBlockEncoder: 2-14        [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-50                 [-1, 512, 4, 4]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-51            [-1, 512, 4, 4]           1,024\n",
       "|    |    └─ReLU: 3-52                   [-1, 512, 4, 4]           --\n",
       "|    |    └─Conv2d: 3-53                 [-1, 512, 4, 4]           2,359,296\n",
       "|    |    └─BatchNorm2d: 3-54            [-1, 512, 4, 4]           1,024\n",
       "├─Sequential: 1-7                        [-1, 128, 1, 1]           --\n",
       "|    └─Conv2d: 2-15                      [-1, 128, 1, 1]           1,048,704\n",
       "|    └─BatchNorm2d: 2-16                 [-1, 128, 1, 1]           256\n",
       "|    └─Tanh: 2-17                        [-1, 128, 1, 1]           --\n",
       "==========================================================================================\n",
       "Total params: 21,922,496\n",
       "Trainable params: 21,922,496\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.06\n",
       "Forward/backward pass size (MB): 50.13\n",
       "Params size (MB): 83.63\n",
       "Estimated Total Size (MB): 133.82\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.resnet import *\n",
    "model = Resnet18Encoder(in_size = (1, 128, 128))\n",
    "model = model.to(device)\n",
    "model\n",
    "from torchsummary import summary\n",
    "summary(model, (1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OW2G7k2uSpCv"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = SequentialClassifier(input_dim=28, emb_dim=64, hidden_dim=128, num_layers=2, mode=\"zeros\")\n",
    "model = latent_lstm(input_dim=64, out_dim=128, hidden_dim=128, num_layers=2, mode=\"zeros\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvW8WI1TS0Rv",
    "outputId": "0dc0f490-9716-46c1-8d49-3d50768cdfbb"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBqqeLdNcoHt"
   },
   "source": [
    "#**Moving MNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9FeJXylxcr_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "# from Seq2Seq import Seq2Seq\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import io\n",
    "import imageio\n",
    "from ipywidgets import widgets, HBox\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MovingMNIST = np.load('mnist_test_seq.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MovingMNIST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader,test_loader = MMNIST(seq_first = False,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "b = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =[]\n",
    "for i in b:\n",
    "    x.append(i)\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x)):\n",
    "    x[i] = x[i].unsqueeze(0)\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x[0]\n",
    "for t in x[1:]:\n",
    "    y = torch.cat([y,t],0)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualizations import *\n",
    "show_gif_batch(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357,
     "referenced_widgets": [
      "7493461413af4bc6b6dc7be40466a3dd",
      "cefa09520ae64b96b609ac5d104a5770",
      "304107e3a62e4606a0c1fd76e97d0834",
      "e5e2d179eb3d4d098445bcd0f6f7f723",
      "f51140542c88454faff52395fa81f221",
      "ab951f501854459989369672bff404d7",
      "58a8bfd0ed184b8281bb3c79ad89a82c",
      "5b579c863052432b996fdacf1f4816b4",
      "a0d2588f098c4fa093ec8d852ce0f8a3",
      "b4e2241b0502428aa46d9b95639bbbb5",
      "458d62e0d9f74aca94266c7028f438ad",
      "0dbd6a91afa4403a8e2cb2953834be33",
      "8c68afcfff9a49b8ae5a486d4ac341cb",
      "b3a8817fa5514bf99db9cb8605f56dfe",
      "50aae3e4712c4bf7aaa377bed1c1c2a2",
      "42ba00e1517e43b296c988e34d454619",
      "27feb1ee56554afd863fed00e0796294",
      "4e55b95a55684eb0822d0afcb31ea1d0",
      "4dbed72f4183441f86e95fd3dd5e0f5a",
      "0dce2e75e9be4e6b982ef140f64d453d",
      "6855edbc8c26499b9d2d9d3afe83f30f",
      "79449a0f56544b7f99f45341c8d52148",
      "5411657399324d3a8bdd09b3f813e01f",
      "21cd805c6ff2484488fb768b868e5b9b",
      "5e296796e9fd4fc29df6b81344e92975",
      "e972f67898564fadaa33be85038f1946"
     ]
    },
    "id": "0la0TcGm_dwX",
    "outputId": "1476dc76-9de5-4b0e-f55e-60c183b524fb"
   },
   "outputs": [],
   "source": [
    "# Reverse process before displaying\n",
    "future_batch = future_batch.cpu().numpy() * 255.0     \n",
    "for video in future_batch.squeeze(1)[:5]:          # Loop over videos\n",
    "    with io.BytesIO() as gif:\n",
    "        imageio.mimsave(gif,video.astype(np.uint8),\"GIF\",fps=5)\n",
    "        past = Box(children=[widgets.Image(value=gif.getvalue())], layout=box_layout)\n",
    "        display(VBox([past]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sFpWdLF_6at"
   },
   "source": [
    "#**Training Fixed Prior Video Generation Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2O6EZhEB36U"
   },
   "outputs": [],
   "source": [
    "#to be added in config\n",
    "batch_size=100\n",
    "past_frames = 10\n",
    "future_frames = 10\n",
    "z_dim = 10\n",
    "g_dim = 128\n",
    "lr = 0.002\n",
    "beta = 0.0001\n",
    "hidden_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5y9pFL-ACS0"
   },
   "outputs": [],
   "source": [
    "encoder = DCGANEncoder()\n",
    "decoder = DCGANDecoder()\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "\n",
    "predictor = predictor_lstm(g_dim+z_dim, g_dim, hidden_dim, num_layers=2)\n",
    "posterior = latent_lstm(g_dim, z_dim, hidden_dim, num_layers=1)\n",
    "predictor = predictor.to(device)\n",
    "posterior = posterior.to(device)\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)\n",
    "predictor_optimizer = torch.optim.Adam(predictor.parameters(), lr=lr, betas = (0.9, 0.999))\n",
    "posterior_optimizer = torch.optim.Adam(posterior.parameters(), lr=lr, betas = (0.9, 0.999))\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=lr, betas = (0.9, 0.999))\n",
    "decoder_optimizer = torch.optim.Adam(posterior.parameters(), lr=lr, betas = (0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6g54h_dLH7QD"
   },
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "mse_loss = nn.MSELoss()\n",
    "# import torch.nn.functional as F\n",
    "def kld_loss(mu, log_var):\n",
    "    \"\"\"\n",
    "    Combined loss function for joint optimization of \n",
    "    prediction and ELBO\n",
    "    \"\"\"\n",
    "    # mse = F.mse_loss(predicted, real, reduction=\"sum\")\n",
    "#     recons_loss = F.binary_cross_entropy(recons.view(b_size,-1), target.view(b_size,-1), reduction='sum')\n",
    "    elbo = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    elbo /= batch_size\n",
    "    # total_loss = mse + elbo*beta\n",
    "    return elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VplKUVgNR9md"
   },
   "outputs": [],
   "source": [
    "def train_epoch(x):\n",
    "    predictor.zero_grad()\n",
    "    posterior.zero_grad()\n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "\n",
    "    # print(\"hello\")\n",
    "\n",
    "    h_seq = [encoder(x[i]) for i in range(past_frames+future_frames)]\n",
    "    # print(h_seq[0][0].shape)\n",
    "    mse =0\n",
    "    kld = 0\n",
    "    for i in range(1,past_frames+future_frames):\n",
    "        h_target = h_seq[i][0]\n",
    "        if i<past_frames:\n",
    "            h, skip = h_seq[i-1]\n",
    "        else:\n",
    "            h = h_seq[i-1][0]\n",
    "        # print(\"here\")\n",
    "        # print(h_target.shape)\n",
    "        z_t, mu, log_var = posterior(h_target)\n",
    "        # print(\"here\")\n",
    "        # print(z_t.shape)\n",
    "        h_pred = predictor(torch.cat([h, z_t], 1))\n",
    "        x_pred = decoder([h_pred, skip])\n",
    "        mse+=mse_loss(x_pred,x[i])\n",
    "        kld+=kld_loss(mu,log_var)\n",
    "\n",
    "    total_loss = mse + kld*beta\n",
    "    total_loss.backward()\n",
    "\n",
    "    predictor_optimizer.step()\n",
    "    posterior_optimizer.step()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return mse.data.cpu().numpy()/(past_frames+future_frames), kld.data.cpu().numpy()/(past_frames+future_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "o5_wOZNKYhLW",
    "outputId": "9f4f30f4-0d6c-403b-bf61-d70343c518b3"
   },
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "for i in range(num_epochs):\n",
    "    predictor.train()\n",
    "    posterior.train()\n",
    "    encoder.train()\n",
    "    decoder.train() \n",
    "    epoch_mse =0\n",
    "    epoch_kld=0\n",
    "    epoch_loss =0\n",
    "\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for j, images in progress_bar:\n",
    "        images = images.to(device)\n",
    "\n",
    "        bs, nc, s, h, w = images.shape\n",
    "        data = images.view(s, bs, nc, h, w)\n",
    "\n",
    "        mse, kld = train_epoch(data)\n",
    "        epoch_mse+=mse\n",
    "        epoch_kld+=kld\n",
    "        progress_bar.set_description(f\"Epoch {i+1} : mse loss {epoch_mse:.5f}, kld los {epoch_kld: .5f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "bBqqeLdNcoHt"
   ],
   "name": "video-prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0dbd6a91afa4403a8e2cb2953834be33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b3a8817fa5514bf99db9cb8605f56dfe"
      ],
      "layout": "IPY_MODEL_8c68afcfff9a49b8ae5a486d4ac341cb"
     }
    },
    "0dce2e75e9be4e6b982ef140f64d453d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ImageModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ImageModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ImageView",
      "format": "png",
      "height": "",
      "layout": "IPY_MODEL_6855edbc8c26499b9d2d9d3afe83f30f",
      "width": ""
     }
    },
    "21cd805c6ff2484488fb768b868e5b9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "BoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "BoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "BoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e296796e9fd4fc29df6b81344e92975"
      ],
      "layout": "IPY_MODEL_e5e2d179eb3d4d098445bcd0f6f7f723"
     }
    },
    "27feb1ee56554afd863fed00e0796294": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4dbed72f4183441f86e95fd3dd5e0f5a"
      ],
      "layout": "IPY_MODEL_4e55b95a55684eb0822d0afcb31ea1d0"
     }
    },
    "304107e3a62e4606a0c1fd76e97d0834": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "BoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "BoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "BoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f51140542c88454faff52395fa81f221"
      ],
      "layout": "IPY_MODEL_e5e2d179eb3d4d098445bcd0f6f7f723"
     }
    },
    "37574759ccb64992a21fd449b660fb13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42ba00e1517e43b296c988e34d454619": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "458d62e0d9f74aca94266c7028f438ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dbed72f4183441f86e95fd3dd5e0f5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "BoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "BoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "BoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dce2e75e9be4e6b982ef140f64d453d"
      ],
      "layout": "IPY_MODEL_e5e2d179eb3d4d098445bcd0f6f7f723"
     }
    },
    "4e55b95a55684eb0822d0afcb31ea1d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50aae3e4712c4bf7aaa377bed1c1c2a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ImageModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ImageModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ImageView",
      "format": "png",
      "height": "",
      "layout": "IPY_MODEL_42ba00e1517e43b296c988e34d454619",
      "width": ""
     }
    },
    "5411657399324d3a8bdd09b3f813e01f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58a8bfd0ed184b8281bb3c79ad89a82c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0d2588f098c4fa093ec8d852ce0f8a3"
      ],
      "layout": "IPY_MODEL_5b579c863052432b996fdacf1f4816b4"
     }
    },
    "5b579c863052432b996fdacf1f4816b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e296796e9fd4fc29df6b81344e92975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ImageModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ImageModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ImageView",
      "format": "png",
      "height": "",
      "layout": "IPY_MODEL_e972f67898564fadaa33be85038f1946",
      "width": ""
     }
    },
    "6855edbc8c26499b9d2d9d3afe83f30f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7493461413af4bc6b6dc7be40466a3dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_304107e3a62e4606a0c1fd76e97d0834"
      ],
      "layout": "IPY_MODEL_cefa09520ae64b96b609ac5d104a5770"
     }
    },
    "79449a0f56544b7f99f45341c8d52148": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_21cd805c6ff2484488fb768b868e5b9b"
      ],
      "layout": "IPY_MODEL_5411657399324d3a8bdd09b3f813e01f"
     }
    },
    "7a82bc2cf62440939d84fa17789a06d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ImageModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ImageModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ImageView",
      "format": "png",
      "height": "",
      "layout": "IPY_MODEL_b96d5d8896b44ab5918e3f0748fa768a",
      "width": ""
     }
    },
    "8a3be34d5abc465086a6f993232c85c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ImageModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ImageModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ImageView",
      "format": "png",
      "height": "",
      "layout": "IPY_MODEL_937bc8ae810f4e4981287e34a9ff3ec0",
      "width": ""
     }
    },
    "8c68afcfff9a49b8ae5a486d4ac341cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "937bc8ae810f4e4981287e34a9ff3ec0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0d2588f098c4fa093ec8d852ce0f8a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "BoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "BoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "BoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4e2241b0502428aa46d9b95639bbbb5"
      ],
      "layout": "IPY_MODEL_e5e2d179eb3d4d098445bcd0f6f7f723"
     }
    },
    "ab951f501854459989369672bff404d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3a8817fa5514bf99db9cb8605f56dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "BoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "BoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "BoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_50aae3e4712c4bf7aaa377bed1c1c2a2"
      ],
      "layout": "IPY_MODEL_e5e2d179eb3d4d098445bcd0f6f7f723"
     }
    },
    "b4e2241b0502428aa46d9b95639bbbb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ImageModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ImageModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ImageView",
      "format": "png",
      "height": "",
      "layout": "IPY_MODEL_458d62e0d9f74aca94266c7028f438ad",
      "width": ""
     }
    },
    "b96d5d8896b44ab5918e3f0748fa768a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cefa09520ae64b96b609ac5d104a5770": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5e2d179eb3d4d098445bcd0f6f7f723": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": "row",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e727ed3736704c3b867e7c8fac64e3a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a3be34d5abc465086a6f993232c85c5",
       "IPY_MODEL_7a82bc2cf62440939d84fa17789a06d7"
      ],
      "layout": "IPY_MODEL_37574759ccb64992a21fd449b660fb13"
     }
    },
    "e972f67898564fadaa33be85038f1946": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f51140542c88454faff52395fa81f221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ImageModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ImageModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ImageView",
      "format": "png",
      "height": "",
      "layout": "IPY_MODEL_ab951f501854459989369672bff404d7",
      "width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
