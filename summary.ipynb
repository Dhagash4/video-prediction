{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Video Prediction Project - Lab CudaVision**\n",
    "* Amit Kumar Rana\n",
    "* Dhagash Desai\n",
    "* Lina Hashem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [1. Import Required Modules](#sec_1)\n",
    "* [2. Datasets](#sec_2)\n",
    "    * [2.1 Moving MNIST](#sec_2_1)\n",
    "    * [2.2 KTH](#sec_2_2)\n",
    "    * [2.3 Train/Test Dotaloader Statistics](#sec_2_3)\n",
    "* [3. Models Architectures](#sec_3)\n",
    "    * [3.1 Resnet18-style Encoder-Decoder](#sec_3_1)\n",
    "    * [3.2 VGG19-style Encoder-Decoder](#sec_3_2)\n",
    "    * [3.3 DCGAN-style Encoder-Decoder](#sec_3_3)\n",
    "    * [3.4 ConvLSTM ](#sec_3_4)\n",
    "    * [3.5 Models #Parameters Statistics](#sec_3_5)\n",
    "* [4. Training Experiments](#sec_4)\n",
    "    * [Training model](#sec_4_1)\n",
    "    * [Visualizing Logs](#sec_4_2)\n",
    "* [5. Results](#sec_5)\n",
    "    * [5.1 Results on MMNIST](#sec_5_1)\n",
    "        * [5.1.1 Visualize Best Metrices](#sec_5_1_1)\n",
    "        * [5.1.2 Visualize Output for Random Samples](#sec_5_1_2)\n",
    "        * [5.1.3 Models Comparison](#sec_5_1_3)\n",
    "    * [5.2 Results on KTH ](#sec_5_2)\n",
    "        * [5.2.1 Visualize Best Metrices](#sec_5_2_1)\n",
    "        * [5.2.2 Visualize Output for Random Samples](#sec_5_2_2)\n",
    "        * [5.2.3 Models Comparison](#sec_5_2_3)\n",
    "* [6. References](#sec_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    ".\n",
    "├── checkpoints         # saving trained models\n",
    "├── configs             # configs used for different experiments\n",
    "├── data                # data directory \n",
    "│   └── KTH\n",
    "│   └── MMNIST          \n",
    "├── model_eval          # scripts for evaluating trained models\n",
    "├── models              # building blocks of the model \n",
    "├── metrics_data        # stored data of computed metrics\n",
    "├── results             # some images/GIFs computed from trained model\n",
    "├── tboard_logs         # logs from our experiments\n",
    "├── utils               # contains trainer to train model and some extra functionalities\n",
    "└── eval.py             \n",
    "└── train.py\n",
    "└── summary.ipynb\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Importing Required Module <a class=\"anchor\" id=\"sec_1\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from prettytable import PrettyTable\n",
    "from utils.visualizations import save_grid_batch, save_gif_batch\n",
    "from utils.utils import eval_dataset, count_model_params\n",
    "from models.resnet import Resnet18Encoder, Resnet18Decoder\n",
    "from models.vgg import VGGEncoder, VGGDecoder\n",
    "from models.dcgan import DCGANEncoder, DCGANDecoder\n",
    "from models.predictorLSTM import predictor\n",
    "from eval import eval\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Datasets <a class=\"anchor\" id=\"sec_2\"></a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **2.1 Moving MNIST <a class=\"anchor\" id=\"sec_2_1\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmnist_test_loader = eval_dataset(dataset = \"MMNIST\", batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(mmnist_test_loader))\n",
    "print(\"batch shape: (seq_len, batch_size, channels, height, width\")\n",
    "sample_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_grid_batch(sample_batch, nsamples=5, text = \"mmnist_test\", show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_gif_batch(sample_batch, nsamples =5, text = \"mmnist_test\", show =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **2.2 KTH <a class=\"anchor\" id=\"sec_2_2\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kth_test_loader = eval_dataset(dataset = \"KTH\", batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(kth_test_loader))\n",
    "print(\"batch shape: (seq_len, batch_size, channels, height, width\")\n",
    "sample_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_grid_batch(sample_batch, nsamples=5, text = \"kth_test\", show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_gif_batch(sample_batch, nsamples =5, text = \"kth_test\", show =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Models Architectures <a class=\"anchor\" id=\"sec_3\"></a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **3.1 Resnet18-style Encoder-Decoder <a class=\"anchor\" id=\"sec_3_1\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_encoder = Resnet18Encoder()\n",
    "resnet_encoder = resnet_encoder.to(device)\n",
    "resnet_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_decoder = Resnet18Decoder(skip_connection=False)\n",
    "resnet_decoder = resnet_decoder.to(device)\n",
    "resnet_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **3.2 VGG19-style Encoder-Decoder <a class=\"anchor\" id=\"sec_3_2\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_encoder = VGGEncoder()\n",
    "vgg_encoder = vgg_encoder.to(device)\n",
    "vgg_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_decoder = VGGDecoder(skip_connection=False)\n",
    "vgg_decoder = vgg_decoder.to(device)\n",
    "vgg_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **3.3 DCGAN-style Encoder-Decoder <a class=\"anchor\" id=\"sec_3_3\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan_encoder = DCGANEncoder()\n",
    "dcgan_encoder = dcgan_encoder.to(device)\n",
    "dcgan_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan_decoder = DCGANDecoder(skip_connection=False)\n",
    "dcgan_decoder = dcgan_decoder.to(device)\n",
    "dcgan_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **3.4 ConvLSTM <a class=\"anchor\" id=\"sec_3_4\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_lstm = predictor(batch_size= 20, device = device, mode=\"zeros\", num_layers=2)\n",
    "predictor_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **3.5 Models Paramters Statistics <a class=\"anchor\" id=\"sec_3_5\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_encoder_params = count_model_params(resnet_encoder)\n",
    "resnet_decoder_params = count_model_params(resnet_decoder)\n",
    "resnet_decoder_skip = Resnet18Decoder(skip_connection=True).to(device)\n",
    "resnet_decoder_skip_params = count_model_params(resnet_decoder_skip)\n",
    "\n",
    "vgg_encoder_params = count_model_params(vgg_encoder)\n",
    "vgg_decoder_params = count_model_params(vgg_decoder)\n",
    "vgg_decoder_skip = VGGDecoder(skip_connection=True).to(device)\n",
    "vgg_decoder_skip_params = count_model_params(vgg_decoder_skip)\n",
    "\n",
    "dcgan_encoder_params = count_model_params(dcgan_encoder)\n",
    "dcgan_decoder_params = count_model_params(dcgan_decoder)\n",
    "dcgan_decoder_skip = DCGANDecoder(skip_connection=True).to(device)\n",
    "dcgan_decoder_skip_params = count_model_params(dcgan_decoder_skip)\n",
    "\n",
    "convlstm_2_params = count_model_params(predictor_lstm)\n",
    "predictor_lstm_3 = predictor(batch_size= 20, device = device, mode=\"zeros\", num_layers=3)\n",
    "convlstm_3_params = count_model_params(predictor_lstm_3)\n",
    "\n",
    "\n",
    "resnet_params_2 = count_model_params(resnet_encoder) + count_model_params(resnet_decoder) + count_model_params(predictor_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_table = PrettyTable()\n",
    "params_table.field_names = [\"Model Type\", \"#layers in ConvLSTM\", \"Skip Connection\", \"num parametes\"]\n",
    "params_table.add_row([\"Resnet18\", 2, False, resnet_encoder_params+resnet_decoder_params+convlstm_2_params])\n",
    "params_table.add_row([\"Resnet18\", 2, True, resnet_encoder_params+resnet_decoder_skip_params+convlstm_2_params])\n",
    "params_table.add_row([\"Resnet18\", 3, False, resnet_encoder_params+resnet_decoder_params+convlstm_3_params])\n",
    "params_table.add_row([\"Resnet18\", 3, True, resnet_encoder_params+resnet_decoder_skip_params+convlstm_3_params])\n",
    "\n",
    "params_table.add_row([\"VGG19\", 2, False, vgg_encoder_params+vgg_decoder_params+convlstm_2_params])\n",
    "params_table.add_row([\"VGG19\", 2, True, vgg_encoder_params+vgg_decoder_skip_params+convlstm_2_params])\n",
    "params_table.add_row([\"VGG19\", 3, False, vgg_encoder_params+vgg_decoder_params+convlstm_3_params])\n",
    "params_table.add_row([\"VGG19\", 3, True, vgg_encoder_params+vgg_decoder_skip_params+convlstm_3_params])\n",
    "\n",
    "params_table.add_row([\"DCGAN\", 2, False, dcgan_encoder_params+dcgan_decoder_params+convlstm_2_params])\n",
    "params_table.add_row([\"DCGAN\", 2, False, dcgan_encoder_params+dcgan_decoder_skip_params+convlstm_2_params])\n",
    "params_table.add_row([\"DCGAN\", 3, False, dcgan_encoder_params+dcgan_decoder_params+convlstm_3_params])\n",
    "params_table.add_row([\"DCGAN\", 3, False, dcgan_encoder_params+dcgan_decoder_skip_params+convlstm_3_params])\n",
    "\n",
    "params_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Training Experiments <a class=\"anchor\" id=\"sec_4\"></a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* configs can be modified to train models from all possible combinations.\n",
    "* configs for our training are located in configs folder\n",
    "* For demo purpose we created summary_config.yaml \n",
    "* Logs can be visualized using %tensorboad --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train.py -c configs/summary_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Results <a class=\"anchor\" id=\"sec_5\"></a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "* It takes longer time to compute evalutation metrics on system without cuda support\n",
    "* All the images will be stored in results folder\n",
    "* Data about metrics will be stored in metrics_data folder with following row order: LPIPS, SSIM, PSNR, MSE, MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.1 Results on MMNIST <a class=\"anchor\" id=\"sec_5_1\"></a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.1.1 Visualizae Best Metrices <a class=\"anchor\" id=\"sec_5_1_1\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = \"checkpoints/mmnist_resnet_2_lpips_resnet_convlstm/model_90.pth\"\n",
    "evaluation = eval(model_path = SAVED_MODEL_PATH)\n",
    "evaluation.visualize_best_metrices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.1.2 Visualizae Output for Random Samples <a class=\"anchor\" id=\"sec_5_1_2\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_batch = next(iter(evaluation.test_loader)).to(device)\n",
    "gt_seq, pred_seq = evaluation.generate_future_sequences(random_batch)\n",
    "save_grid_batch(random_batch, torch.cat((gt_seq,pred_seq),dim=0), batch_first=False, text=\"random_batch_mmnist\",show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.1.3 Models Comparison <a class=\"anchor\" id=\"sec_5_1_3\"></a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plot_mmnist_compare.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2 Results on KTH <a class=\"anchor\" id=\"sec_5_2\"></a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.2.1 Visualizae Best Metrices <a class=\"anchor\" id=\"sec_5_2_1\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = \"checkpoints/kth/model_170.pth\"\n",
    "evaluation = eval(model_path = SAVED_MODEL_PATH)\n",
    "evaluation.visualize_best_metrices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.2.2 Visualizae Output for Random Samples <a class=\"anchor\" id=\"sec_5_2_2\"></a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_batch = next(iter(evaluation.test_loader)).to(device)\n",
    "gt_seq, pred_seq = evaluation.generate_future_sequences(random_batch)\n",
    "save_grid_batch(random_batch, torch.cat((gt_seq,pred_seq),dim=0), batch_first=False, text=\"random_batch_kth\",show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5.2.3 Models Comparison <a class=\"anchor\" id=\"sec_5_2_3\"></a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plot_kth_compare.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. References <a class=\"anchor\" id=\"sec_6\"></a>**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
